{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Install Required Libraries ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !python3 -m pip install --upgrade pip\n",
    "# !source .venv/bin/activate\n",
    "# !pip install numpy pandas matplotlib seaborn tensorflow keras xgboost scikit-learn fastapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load and Prepare Data ###\n",
    "\n",
    "Let's assume we have a dataset (cash_flow_data.csv) with the following columns:\n",
    "\n",
    " - date: Daily timestamps\n",
    " - sales: Revenue from sales\n",
    " - expenses: Daily expenses\n",
    " - cash_inflow: Cash received\n",
    " - cash_outflow: Cash spent\n",
    " - net_cash_flow: cash_inflow - cash_outflow (target variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"../cashflow_2024.csv\", parse_dates=[\"Date\"])\n",
    "df.set_index(\"Date\", inplace=True)\n",
    "\n",
    "# Fill missing values\n",
    "# df.fillna(method=\"ffill\", inplace=True)\n",
    "df.ffill(inplace=True)\n",
    "\n",
    "# Create lag features (past cash flow as features)\n",
    "for lag in range(1, 8):  # 7-day lag\n",
    "    df[f\"net_cash_flow_lag_{lag}\"] = df[\"net_cash_flow\"].shift(lag)\n",
    "\n",
    "# Drop missing values (due to lagging)\n",
    "df.dropna(inplace=True)\n",
    "del df['Activity']\n",
    "\n",
    "# Check dataset\n",
    "df.head()\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Feature Engineering ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Add time-based features\n",
    "df[\"day_of_week\"] = df.index.dayofweek\n",
    "df[\"month\"] = df.index.month\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df)\n",
    "\n",
    "# Convert back to DataFrame\n",
    "df_scaled = pd.DataFrame(scaled_features, index=df.index, columns=df.columns)\n",
    "\n",
    "# Split into training and testing\n",
    "train_size = int(len(df) * 0.8)\n",
    "train, test = df_scaled.iloc[:train_size], df_scaled.iloc[train_size:]\n",
    "\n",
    "# Define target variable\n",
    "X_train, y_train = train.drop(columns=[\"net_cash_flow\"]), train[\"net_cash_flow\"]\n",
    "X_test, y_test = test.drop(columns=[\"net_cash_flow\"]), test[\"net_cash_flow\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train an XGBoost Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Train XGBoost model\n",
    "model_xgb = xgb.XGBRegressor(objective=\"reg:squarederror\", n_estimators=100, learning_rate=0.1)\n",
    "model_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = model_xgb.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost MAE: {mae_xgb}\")\n",
    "\n",
    "# Plot actual vs predicted\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(test.index, y_test, label=\"Actual\", color=\"blue\")\n",
    "plt.plot(test.index, y_pred_xgb, label=\"Predicted\", color=\"red\")\n",
    "plt.legend()\n",
    "plt.title(\"XGBoost Forecasting - Cash Flow\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Train an LSTM Model (Deep Learning) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Reshape for LSTM input\n",
    "scaler_lstm = MinMaxScaler()\n",
    "scaled_lstm = scaler_lstm.fit_transform(df)\n",
    "\n",
    "# Create sequences for LSTM (past 7 days â†’ next day prediction)\n",
    "def create_sequences(data, n_steps=7):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - n_steps):\n",
    "        X.append(data[i:i+n_steps, :-1])  # All columns except target\n",
    "        y.append(data[i+n_steps, -1])  # Target column\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_lstm, y_lstm = create_sequences(scaled_lstm)\n",
    "X_train_lstm, X_test_lstm = X_lstm[:train_size], X_lstm[train_size:]\n",
    "y_train_lstm, y_test_lstm = y_lstm[:train_size], y_lstm[train_size:]\n",
    "\n",
    "# Define LSTM model\n",
    "model_lstm = Sequential([\n",
    "    LSTM(50, activation='relu', return_sequences=True, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(50, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile and train\n",
    "model_lstm.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "model_lstm.fit(X_train_lstm, y_train_lstm, epochs=20, batch_size=16, validation_data=(X_test_lstm, y_test_lstm))\n",
    "\n",
    "# Predictions\n",
    "y_pred_lstm = model_lstm.predict(X_test_lstm)\n",
    "\n",
    "# Rescale predictions back to original values\n",
    "y_pred_lstm = scaler_lstm.inverse_transform(np.concatenate((X_test_lstm[:, -1, :], y_pred_lstm), axis=1))[:, -1]\n",
    "\n",
    "# Evaluate LSTM\n",
    "mae_lstm = mean_absolute_error(y_test_lstm, y_pred_lstm)\n",
    "print(f\"LSTM MAE: {mae_lstm}\")\n",
    "\n",
    "# Plot actual vs predicted\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(test.index[-len(y_pred_lstm):], y_test_lstm, label=\"Actual\", color=\"blue\")\n",
    "plt.plot(test.index[-len(y_pred_lstm):], y_pred_lstm, label=\"Predicted\", color=\"red\")\n",
    "plt.legend()\n",
    "plt.title(\"LSTM Forecasting - Cash Flow\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Deploy the Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "import numpy as np\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/predict_cash_flow/\")\n",
    "def predict_cash_flow(features: str):\n",
    "    features_array = np.array([float(x) for x in features.split(\",\")]).reshape(1, -1)\n",
    "    prediction = model_xgb.predict(features_array)[0]\n",
    "    return {\"predicted_cash_flow\": float(prediction)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
